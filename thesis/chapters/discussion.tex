\chapter{Diskussion der Ergebnisse}


Die unterschiedlichen Bewertungsmetriken wurden für eine Q\&A-Plattoform mit $R_\gamma = 0$ und einer News-Plattform mit $R_\gamma = 2$, mit jeweils den User*innenmeinungsfunktionen Konsens und Dissens simuliert.

Bereits die Wahl des Votingsystems bzw. des Bewertungsraums hat Einfluss auf die Fairness einer Bewertungsmetrik. In dieser Simulation ist ein größerer Bewertungsraum von $V_N = 2$ in den meisten Fällen fairer. Jedoch gibt es insbesondere auf News-Plattformen einige Konfigurationen mit $V_N = 1$ welche besser abschneiden. Es lässt sich nicht mit Gewissheit sagen, welcher Bewertungsraum zur einer faireren Bewertungsmetrik führt, außerdem ist es interessant, größere $V_N$ zu untersuchen.

Die in \cite{Luu} vorgeschlagene zufällige Abweichung führt in dieser Simulation zur Verbesserung von Metriken auf News- und Dissens-Plattformen. Der aggregierte Gini-Koeffizient $T(G)$ und die Anzahl der Posts ohne Betrachtungen kann signifikant reduziert werden, während der aggregierte $nDCG$ $T(nDCG)$ stabil bleibt. Hier empfiehlt sich die Anwendung einer zufälligen Abweichung. 

In \cite{miller} wird der Wilson-Score $\tau_{wilson}$ vorgeschlagen um Up- und Downvotes eines Posts zu evaluieren. In der Simulation zeigt sich, dass der Wilson Score nicht in allen Fällen der Differenz von Up- und Downvotes $\tau_{diff}$ überlegen ist. Auf einer Q\&A-Plattform auf der Konsens herrscht ist die $\tau_{diff}$ überlegen.

Bewertungsmetriken liefern bessere Ergebnisse, wenn Posts mit einem Initialscore $\iota_0 > 0$ ausgestattet werden. Die Wahl des besten Initialscores ist von der Bewertungsmetrik abhängig. Bei dem Initialscore $\iota_0 = 0$ werden die neuen Posts unter allen bereits existierenden Posts angezeigt und erhalten somit nur sehr wenige Betrachtungen. Sobald $\iota_0 > 0$ gewählt wird, erhalten neue Posts von Beginn an Betrachtungen und gute Posts so die Chance gute Bewertungen zu erhalten.
Für die Reddit Hot Metrik konnte aufgrund der Komplexität der Metrik der Initialscore nur marginal untersucht werden, es ist jedoch zu vermuten, dass dieser, wie bei den drei weiteren Metriken, weder kleiner noch größer als der Score sämtlicher Posts der Bewertungsmetrik zu wählen ist.

Die Wahl der Gravität hat einen großen Einfluss auf die Fairness von Bewertungsmetriken, diese sollte daher mit Bedacht gewählt werden. Während auf einer Q\&A-Plattform kleine Gravitäten $\gamma = 0 + \epsilon, \epsilon \leq 0.5$ vorteilhaft sind, ist auf einer News-Plattform mit $R_\gamma = 2$ am besten $\gamma = 2$ zu wählen. Möglicherweise ist für $R_\gamma \approx \gamma$ die Bewertungsmetrik am fairsten.

Die Evaluationsparameter $T(G)$ und $P_{v=0}$ sind mit einem Spearman-Koeffizienten von $0.92$ in der \texttt{Überblick}-Konfiguration sehr stark korreliert. Der Gini-Koeffizient achtet implizit auf die Anzahl der Posts ohne Betrachtungen, worauf diese hohe Korrelation zurückzuführen ist. %Der Gini-Koeffizient findet viel Anwendung in der existierenden Literatur, da sich die Anzahl der Posts ohne Betrachtungen jedoch direkt aus der Fairnessdefinition einer Bewertungsmetrik ergibt wird $P_{v=0}$ vorgezogen.

In dieser Arbeit wurde der sehr große Featureraum nicht vollständig exploriert. Einzelne Metrikparameter wie der Initialscore werden nur unter bestimmten Modellkonfigurationen simuliert und verglichen. Es ist möglich, dass Kombinationen von Metrikparametern sehr gute Ergebnisse liefern, zu diesen aber keine Simulation ausgeführt wurde und sie nicht entdeckt wurden. Mit Gewissheit kann nicht gesagt werden, welche Bewertungsmetirk unter einer bestimmten Konfiguration auf einer der Plattformarten am fairsten ist. Es zeigt sich jedoch, dass durch die Wahl der Bewertungsmetrik die Fairness der Sortierung von Posts beeinflusst und damit die fairste Bewertungsmetrik im Featureraum gefunden werden kann.


\paragraph{Einfluss der Modell- und User*innenparameter}

Die User*innenmeinungsfunktion kann, je nach Plattform die modelliert werden soll, als Konsens oder als Dissens gewählt werden. Wird eine News-Plattform modelliert, sind die Ergebnisse im Konsens und Dissens sehr stark korreliert. Die hohe Relevanzgravität auf der News-Plattform scheint die unterschiedlichen Meinungsfunktionen zu egalisieren. Außerdem betrachten die  User*innenmeinungsfunktionen nur die Qualität eines Postes und nicht das Alter, dieses wird jedoch bei der Berechnung der Relevanz eines Posts bestraft. Es entsteht eine grundsätzliche Abweichung zwischen der Relevanz und Meinungsfunktionen von älteren Posts. Diese kann in einer zukünftigen Implementierung durch das Einfließen der Relevanzgravität in die User*innenmeinungsfunktion verhindert werden.

Die Erhöhung der Iterationslänge führt erwartungsgemäß zu einer Verringerung der Varianz und damit Präzisierung der betrachteten Ergebnisparameter. Im Fall von Q\&A-Plattformen werden einzelne Bewertungsmetriken von hohen Iterationslängen bevorzugt, sie liefern dort bessere Ergebnisse. Daher ist es weiterhin interessant, die Bewertungsmetriken unter höheren Iterationslängen zu untersuchen und die Langzeitperformance zu analysieren.

Die Vergleichbarkeit der Ergebnisse ist nicht unmittelbar abhängig von der Wahl der User*innenparameter. Zwar können die Ergebnisse zum Beispiel durch die Wahl der Konzentrationsverteilung bezüglich des aggregierten Gini-Koeffizienten verschoben werden, jedoch erfahren dann sämtliche Modellkonfigurationen diese Verschiebung, sodass keine einzelnen Modellkonfigurationen durch die bestimmte Wahl der User*innenparameter bevorteilt wird.

Erfreulicherweise scheinen die Änderungen des Qualitätsraum ebenfalls keinen Einfluss auf die Vergleichbarkeit der Ergebnisse zu haben, keine Bewertungsmetrik wird durch die bestimmte Wahl eines Qualitätsraums bevorteilt. Der Qualitätsraum ist nicht bekannt und muss artifiziell erzeugt werden, ohne Einfluss auf die Vergleichbarkeit der Ergebnisse kann der Qualitätsraum sinnvoll beliebig gewählt werden.

Auch die Variierung der Post- und User*innenzahlen hat keinen gravierenden Einfluss auf die Vergleichbarkeit der Ergebnisse. Wie zu Erwarten steigt mit zunehmender Postanzahl der Gini-Koeffizient und die Anzahl der Posts ohne Betrachtungen. Auf einer reellen Social Media Plattform ist die Anzahl der User*innen und Posts um ein vielfaches größer als in dieser Simulation. Es ist sicherlich aufschlussreich, sich näher an die reellen Zahlen heranzutasten, um zu überprüfen, ob die Vergleichbarkeit der Ergebnisse erhalten bleibt, sodass in der Simulation weiterhin kleine User*innen- und Postanzahlen verwendet werden können.