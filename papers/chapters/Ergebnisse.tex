\chapter{Ergebnisse}

In diesem Kapitel werden die Ergebnisse der agent*innenbasierten Modellierung vorgestellt.

Mit Blick auf die aufgestellten Kriterien einer fairen Bewertungsmetrik wird in der Auswertung der Koeffizient $\rho$ in Formel \ref{eq:rho} verwendet, welcher die relevanten aggregierten Evaluationsparameter $T(nDCG)$, den Gini-Koeffizienten $T(G)$ und den Anteil der nicht betrachteten Posts $P_{v=0}$ vereint. $\rho$ wird für faire Bewertungsmetriken minimiert.

\begin{equation}
\rho =  1 - (\frac{nDCG}{2} - \frac{G}{4} - \frac{P_{v=0}}{4})
\end{equation}

Voerst werden Modellkonfigurationen unter den vier Fällen mit jeweils der Relevanzgravität $G_R = {0,2} $ und den User*innenmeinungsfunktionen Konsens $R_K$ und Dissens $R_D$ ausgwertet. In Abbildung \ref{fig:cases} links sind $T(G)$, $T(nDCG)$, und $P_{v = 0}$ von Modellen nach der Konfiguration 1 in die vier Fälle eingeteilt. Grau  hinterlegt sind sämtliche Modelle, farblich hervorgehoben die Mittelwerte der unterschiedlichen Modellkonfigurationen. Farblich unterschieden wird zwischen den Bewertungsmetriken. Aus der Korrelationsmatrix rechts in der Abbildung geht hervor, dass $\rho$ der Modelle für die Fälle mit $G_R = 2$ und der Fall $R = R_K$ und $G_R = 2$ stark durch den Spearman-Koeffizienten korreliert sind. 

Im Folgenden werden nur noch die Fälle $R = R_K$ und $G_R = {0,2}$ betrachtet, die drei stark korrelierten Fällen müssen nicht einzeln untersucht werden.


\begin{figure}[!h]
	\label{fig:cases}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/full_model_grouped_scatter.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/full_model_grouped_corr.png"}
	\end{subfigure}
	\caption{Fälle von Plattformen}
\end{figure}


%TODO update config

\section{Größe des Bewertungsvektor}

In Abbildung \ref{fig:bewertungvektor} ist die Modellsimulation mit Konfiguration 1 der Fälle $R = R_K$ und $G_R = {0,2}$ zu sehen . Farblich markiert ist die Größe des Bewertungsvektors. In 64.4\% der Konfigurationen wird mit $B_N = 2$ ein besseres $\rho$ erzielt.

\begin{figure}[!h]
	\label{fig:bewertungsvektor}	
	\includegraphics[width=\textwidth]{"../plots/bewertungsvektor_all.png"}
	\caption{Bewertungsvektor}
\end{figure}

\section{Initialscore}

Abbildung \ref{fig:initscore} zeigt $\rho$ der Konfiguration 1 der beiden beiden Fälle. Auf der x-Achse sind die Bewertungsmetriken aufgetragen, farblich markiert ist der Initalwert. $s_0 = 0$ ist für alle Modellkonfigurationen die schlechteste Wahl.



\begin{figure}[!h]
	\label{fig:initscore}	
	\includegraphics[width=\textwidth]{"../plots/init_score_boxplot.png"}
	\caption{Initialscore}
\end{figure}


Nach Konfiguration 3 ist der Einfluss auf die Bewertungsmetriken des Initialscores dargestellt. In der Konfiguration des  verallgemeinerten Hacker News Metrik wird durch die Erhöhung von $s_0$ $T(G)$ verringert und $T(nDCG)$ erhöht. Für $s_0 > 70$ verringert sich $T(nDCG)$ signifikant. Bei der Aktivitätsmetrik führt eine Erhöhung von $s_0$ zum Abnahme von $P_{v=0}$, $T(nDCG)$ und $T(G)$. In der Viewmetrik wird zwischen $s_0 \in [10,30]$ $T(G)$ und $P_{v=0}$ reduziert, für $s_0 > 30$ wird hauptsächlich $T(nDCG)$ reduziert. Für die Reddit Hot Metrik ist $s_0 = \{0,30000\}$. Für $s_0$ erhalten neue Posts einen höheren Initialscore, als jemals von der Metrik zugewiesen wird. Der hohe Initialwert liefert bessere kleinere $T(G)$, $T(nDCG)$ und $P_{v=0}$. 

Die Variierung des Initialscores wirkt sich auf unterschiedliche Art auf die unterschiedlichen Bewertungsmetriken aus.

\begin{figure}[!htb]
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/init_hn.png}%
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		
		
		\includegraphics[width=\textwidth]{"../plots/init_akt.png"}%
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/init_view.png"}%
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/init_reddit.png"}%
	\end{subfigure}
	\caption{Initialscore in Bewertungsmetriken}
	\label{fig:init_scoring_functions}
\end{figure}


\section{Gravität}

Der Einfluss der Gravität der drei Bewertungsmetriken mit Gravität wird nach Konfiguration 4 in Abbildung \ref{fig:grav} gezeigt. Die Aktivitätsmetrik besitzt bei $G_R = G=0$ den Wert $P_{v=0} = 0.84$. So wird bei der Akitvitätsmetrik das geringste $\rho$ mit $G=0$ erzielt. Für die View- und Hacker News Metrik steigt $\rho$ mit der Erhöhung von $G$ im Fall $G_R = 0$. Für den Fall $G_R = 2$ wird das kleinste $\rho$ mit $G = 0$ für die Bewertungsmetriken Aktivität und Verallgemeinertes Hacker News erzielt. Auf die Viewmetrik hat in diesem Fall die Variierung on $G$ keinen signifikanten Einfluss.

\begin{figure}[!h]
	\label{fig:grav}	
	\includegraphics[width=\textwidth]{"../plots/gravity_box.png"}
	\caption{Gravität}
\end{figure}

\section{Bewertungstransformation}

In Abbildung \ref{fig:trans} ist farblich die verwendete Bewertungstransformation gekennzeichnet. Ein Datenpunkt beschreibt den Mittelwert einer Modellkonfiguration. Es zeigt sich, dass $v_{diff}$ in den meisten Bewertungsmetrikfällen eine größere Varianz bezüglich $\rho$ als $v_{anteil}$ und $v_{wilson}$ Im Fall $R = R_K$ und $G_R = 0$ besitzt $v_{diff}$ jedoch einen geringeren Mittelwert. Im weiteren betrachteten Fall $R = R_K$ und $G_R = 0$ ist die Perfomance von $v_{anteil}$ und $v_{wilson}$ sehr ähnlich und meist besser als $v_{diff}$.  

\begin{figure}[!h]
	\label{fig:trans}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/vote_eval_scatter.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/vote_eval_boxplot.png"}
	\end{subfigure}
	\caption{Bewertungstransformation}
\end{figure}


\section{Zufallsbewertung}


Die Boxplots in Abbildung \ref{fig:zufall} zeigen, dass eine zufällige Abweichung bei allen Metriken außer der verallgemeinerten Hacker News im Fall $G_R = 0$ , zu einer signifikanten Verkleinerung von $P_{v=0}$ und $T(G)$ führt. Dabei führt die $\sigma$-Abweichung zu einer stärkeren Reduktion. Auch $T(nDCG)$ wird bei $G_R = 0$ verringert, wieder stärker durch die $\sigma$-Abweichung. Die Hacker News Metrik reagiert in diesem Fall gering auf die Zufallsabweichung. Im Fall von $G_R = 2$ wirkt sich die Zufallsabweichung nicht signifikant aus.

\begin{figure}[!h]
	\label{fig:zufall}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dev_pwnv.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dev_gini.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dev_ndcg.png"}
	\end{subfigure}
	\caption{Zufallsbewertung mit Konfiguration 4}
\end{figure}


\section{Iterationslänge}

Wird die Iterationslänge $M_N$ varriert hat dies Einfluss auf das Ergebnis. In Abbildung \ref{fig:steps} links oben sind die vier Bewertungsmetriken nach Konfiguration 4 nach $G_R = {1,2}$ dargestellt. Im Fall $G_R = 2$ zeigt sich, dass durch Erhöhung der Iterationsanzahl $T(nDCG)$ und $P_{v=0}$ verkleinert wird. Für den Fall $G_R = 0$ zeigen die drei weiteren Plots die Entwicklung der drei Evaluationsparameter mit steigender Iterationslänge. $T(nDCG)$ wird für die View- und Aktivitätsmetrik größer. Die Varianz von $T(nDCG)$ verringert sich für alle Metriken außer der Hacker News Metrik. $P_{v=0}$ steigt für die Viewmetrik mit steigendem $M_N$. Bei den drei restlichen Metriken wird $P_{v=0}$ und dessen Varianz verringert. Das Ansteigen der Iterationszahl hat nur geringen Einfluss auf $T(G)$, für die Hacker News Metrik wird $T(G)$ geringfügig größer. 




\begin{figure}[!htb]
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/steps_scatter.png}%
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		
		
		\includegraphics[width=\textwidth]{"../plots/steps_ndcg.png"}%
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/steps_pwnv.png"}%
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/steps_gini.png"}%
	\end{subfigure}
	\caption{Unterschiedliche Iterationslängen}
	\label{fig:steps}
\end{figure}



\section{User*innenparameter}

\subsection{User*innenwahrscheinlichkeitsfunktionen}


Dissensrating bringt erwartungsgemäß schlechtere Ergebnisse, 


\section{Bewertungsmetriken}


\section{Modellparameter}

\subsection{Qualitätsraum}

Der Einfluss der Größe des Qualitätsraum $Q_N$ wird in Abbildung \ref{fig:qual} untersucht. 
Auf den Fall $G_R = 0$ hat die Größe nur geringfügig Einfluss, wie auch der Boxplot rechts bestätigt. Im Fall $G_R = 2$ erhöht sich mit $Q_N$ $T(nDCG)$. Auch die Varianz von $T(nDCG)$ verringert sich.a

\begin{figure}[!h]
	\label{fig:qual}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dim_scatter.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dims_box.png"}
	\end{subfigure}
	\caption{Qualitätsdimensionen}
\end{figure}

\subsection{Vorsortierung}

Verlauf kein Scatteplot ist bestimmt interessanter

%\subsection{(Extreme User*innen)}

%gleiche wie vorsorierteung mit verlauf




