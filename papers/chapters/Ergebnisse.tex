\chapter{Ergebnisse}

In diesem Kapitel werden die Ergebnisse der agent*innenbasierten Modellierung vorgestellt.

Mit Blick auf die aufgestellten Kriterien einer fairen Bewertungsmetrik wird in der Auswertung der Koeffizient $\rho$ in Formel \ref{eq:rho} verwendet, welcher die relevanten aggregierten Evaluationsparameter $T(nDCG)$, den Gini-Koeffizienten $T(G)$ und den Anteil der nicht betrachteten Posts $P_{v=0}$ vereint. $\rho$ wird für faire Bewertungsmetriken minimiert.

\begin{equation}
\rho =  1 - (\frac{nDCG}{2} - \frac{G}{4} - \frac{P_{v=0}}{4})
\end{equation}

Voerst werden Modellkonfigurationen unter den vier Fällen mit jeweils der Relevanzgravität $G_R = {0,2} $ und den User*innenmeinungsfunktionen Konsens $R_K$ und Dissens $R_D$ ausgwertet. In Abbildung \ref{fig:cases} links sind $T(G)$, $T(nDCG)$, und $P_{v = 0}$ von Modellen nach der Konfiguration 1 in die vier Fälle eingeteilt. Grau  hinterlegt sind sämtliche Modelle, farblich hervorgehoben die Mittelwerte der unterschiedlichen Modellkonfigurationen. Farblich unterschieden wird zwischen den Bewertungsmetriken. Aus der Korrelationsmatrix rechts in der Abbildung geht hervor, dass $\rho$ der Modelle für die Fälle mit $G_R = 2$ und der Fall $R = R_K$ und $G_R = 2$ stark durch den Spearman-Koeffizienten korreliert sind. 

Im Folgenden werden nur noch die Fälle $R = R_K$ und $G_R = {0,2}$ betrachtet, die drei stark korrelierten Fällen müssen nicht einzeln untersucht werden.


\begin{figure}[!h]
	\label{fig:cases}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/full_model_grouped_scatter.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/full_model_grouped_corr.png"}
	\end{subfigure}
	\caption{Fälle von Plattformen}
\end{figure}


%TODO update config

\section{Größe des Bewertungsvektor}

In Abbildung \ref{fig:bewertungvektor} ist die Modellsimulation mit Konfiguration 1 der Fälle $R = R_K$ und $G_R = {0,2}$ zu sehen . Farblich markiert ist die Größe des Bewertungsvektors. In 64.4\% der Konfigurationen wird mit $B_N = 2$ ein besseres $\rho$ erzielt.

\begin{figure}[!h]
	\label{fig:bewertungsvektor}	
	\includegraphics[width=\textwidth]{"../plots/bewertungsvektor_all.png"}
	\caption{Bewertungsvektor}
\end{figure}

\section{Initialscore}

Abbildung \ref{fig:initscore} zeigt $\rho$ der Konfiguration 1 der beiden beiden Fälle. Auf der x-Achse sind die Bewertungsmetriken aufgetragen, farblich markiert ist der Initalwert. $s_0 = 0$ ist für alle Modellkonfigurationen die schlechteste Wahl.



\begin{figure}[!h]
	\label{fig:initscore}	
	\includegraphics[width=\textwidth]{"../plots/init_score_boxplot.png"}
	\caption{Initialscore}
\end{figure}


Nach Konfiguration 3 ist der Einfluss auf die Bewertungsmetriken des Initialscores dargestellt. In der Konfiguration des  verallgemeinerten Hacker News Metrik wird durch die Erhöhung von $s_0$ $T(G)$ verringert und $T(nDCG)$ erhöht. Für $s_0 > 70$ verringert sich $T(nDCG)$ signifikant. Bei der Aktivitätsmetrik führt eine Erhöhung von $s_0$ zum Abnahme von $P_{v=0}$, $T(nDCG)$ und $T(G)$. In der Viewmetrik wird zwischen $s_0 \in [10,30]$ $T(G)$ und $P_{v=0}$ reduziert, für $s_0 > 30$ wird hauptsächlich $T(nDCG)$ reduziert. Für die Reddit Hot Metrik ist $s_0 = \{0,30000\}$. Für $s_0$ erhalten neue Posts einen höheren Initialscore, als jemals von der Metrik zugewiesen wird. Der hohe Initialwert liefert bessere kleinere $T(G)$, $T(nDCG)$ und $P_{v=0}$. 

Die Variierung des Initialscores wirkt sich auf unterschiedliche Art auf die unterschiedlichen Bewertungsmetriken aus.

\begin{figure}[!htb]
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/init_hn.png}%
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		
		
		\includegraphics[width=\textwidth]{"../plots/init_akt.png"}%
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/init_view.png"}%
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/init_reddit.png"}%
	\end{subfigure}
	\caption{Initialscore in Bewertungsmetriken}
	\label{fig:init_scoring_functions}
\end{figure}


\section{Gravität}

Der Einfluss der Gravität der drei Bewertungsmetriken mit Gravität wird nach Konfiguration 4 in Abbildung \ref{fig:grav} gezeigt. Die Aktivitätsmetrik besitzt bei $G_R = G=0$ den Wert $P_{v=0} = 0.84$. So wird bei der Akitvitätsmetrik das geringste $\rho$ mit $G=0$ erzielt. Für die View- und Hacker News Metrik steigt $\rho$ mit der Erhöhung von $G$ im Fall $G_R = 0$. Für den Fall $G_R = 2$ wird das kleinste $\rho$ mit $G = 0$ für die Bewertungsmetriken Aktivität und Verallgemeinertes Hacker News erzielt. Auf die Viewmetrik hat in diesem Fall die Variierung on $G$ keinen signifikanten Einfluss.

\begin{figure}[!h]
	\label{fig:grav}	
	\includegraphics[width=\textwidth]{"../plots/gravity_box.png"}
	\caption{Gravität}
\end{figure}

\section{Bewertungstransformation}

In Abbildung \ref{fig:trans} ist farblich die verwendete Bewertungstransformation gekennzeichnet. Ein Datenpunkt beschreibt den Mittelwert einer Modellkonfiguration. Es zeigt sich, dass $v_{diff}$ in den meisten Bewertungsmetrikfällen eine größere Varianz bezüglich $\rho$ als $v_{anteil}$ und $v_{wilson}$ Im Fall $R = R_K$ und $G_R = 0$ besitzt $v_{diff}$ jedoch einen geringeren Mittelwert. Im weiteren betrachteten Fall $R = R_K$ und $G_R = 0$ ist die Perfomance von $v_{anteil}$ und $v_{wilson}$ sehr ähnlich und meist besser als $v_{diff}$.  

\begin{figure}[!h]
	\label{fig:trans}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/vote_eval_scatter.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/vote_eval_boxplot.png"}
	\end{subfigure}
	\caption{Bewertungstransformation}
\end{figure}


\section{Zufallsbewertung}


Die Boxplots in Abbildung \ref{fig:zufall} zeigen, dass eine zufällige Abweichung bei allen Metriken außer der verallgemeinerten Hacker News im Fall $G_R = 0$ , zu einer signifikanten Verkleinerung von $P_{v=0}$ und $T(G)$ führt. Dabei führt die $\sigma$-Abweichung zu einer stärkeren Reduktion. Auch $T(nDCG)$ wird bei $G_R = 0$ verringert, wieder stärker durch die $\sigma$-Abweichung. Die Hacker News Metrik reagiert in diesem Fall gering auf die Zufallsabweichung. Im Fall von $G_R = 2$ wirkt sich die Zufallsabweichung nicht signifikant aus.

\begin{figure}[!h]
	\label{fig:zufall}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dev_pwnv.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dev_gini.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dev_ndcg.png"}
	\end{subfigure}
	\caption{Zufallsbewertung mit Konfiguration 4}
\end{figure}


\section{Modellparameter}

\subsection{Iterationslänge}

Wird die Iterationslänge $M_N$ varriert hat dies Einfluss auf das Ergebnis. In Abbildung \ref{fig:steps} links oben sind die vier Bewertungsmetriken nach Konfiguration 4 nach $G_R = {1,2}$ dargestellt. Im Fall $G_R = 2$ zeigt sich, dass durch Erhöhung der Iterationsanzahl $T(nDCG)$ und $P_{v=0}$ verkleinert wird. Für den Fall $G_R = 0$ zeigen die drei weiteren Plots die Entwicklung der drei Evaluationsparameter mit steigender Iterationslänge. $T(nDCG)$ wird für die View- und Aktivitätsmetrik größer. Die Varianz von $T(nDCG)$ verringert sich für alle Metriken außer der Hacker News Metrik. $P_{v=0}$ steigt für die Viewmetrik mit steigendem $M_N$. Bei den drei restlichen Metriken wird $P_{v=0}$ und dessen Varianz verringert. Das Ansteigen der Iterationszahl hat nur geringen Einfluss auf $T(G)$, für die Hacker News Metrik wird $T(G)$ geringfügig größer. 


\begin{figure}[!htb]
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/steps_scatter.png}%
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		
		
		\includegraphics[width=\textwidth]{"../plots/steps_ndcg.png"}%
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/steps_pwnv.png"}%
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/steps_gini.png"}%
	\end{subfigure}
	\caption{Unterschiedliche Iterationslängen}
	\label{fig:steps}
\end{figure}

\subsection{Qualitätsraum}

Der Einfluss der Größe des Qualitätsraum $Q_N$ wird in Abbildung \ref{fig:qual} untersucht. 
Auf den Fall $G_R = 0$ hat die Größe nur geringfügig Einfluss, wie auch der Boxplot rechts bestätigt. Im Fall $G_R = 2$ erhöht sich mit $Q_N$ $T(nDCG)$. Auch die Varianz von $T(nDCG)$ verringert sich.a

\begin{figure}[!h]
	\label{fig:qual}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dim_scatter.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/dims_box.png"}
	\end{subfigure}
	\caption{Qualitätsdimensionen}
\end{figure}


\subsection{User*innen- und Postanzahl}

In Abbildung \ref{fig:start_posts} ist der Einfluss der Anzahl der Startposts nach der \textit{speziellen Modellkonfiguration} dargestellt. Wird die Anzahl der Startposts erhöht, werden die Evaluationsparamater schlechter. Je mehr Posts von Anfang an existieren, desto kleiner ist der Teil den die User*innen schon zu Beginn erfassen können. Die Folge ist die markante Reduzierung von $T(G)$ und $T(nDCG)$. Die Ergebnisse mit unterschiedlicher Anzahl an Startposts sind stark miteinander korreliert. Die Bewertungsmetriken bleiben unabhängig von den Startposts vergleichbar, keine Bewertungsmetrik wird durch die bestimmte Wahl der Startposts bevorteiligt.

Wird die Anzahl der neuen Posts pro Iteration oder die der User*innen variiert, sind die Ergebnisse der unterschiedlichen Anzahlen ebenfalls stark korreliert. Trotzdem ist davon auszugehen, dass mit einer hohen Wahl der Parameter die Realität besser modelliert wird.

\begin{figure}[!h]
	\label{fig:start_posts}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/start_posts_scatter.png"}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/start_posts_box.png"}
	\end{subfigure}
	\caption{Startposts}
\end{figure}


\subsection{Vorsortierung der Posts}

%Verlauf kein Scatteplot ist bestimmt interessanter JA IST INTERESSANTER MUSSTE ABER ERSTMAL IMPLEMENTIEREN DU DULLI

%\subsection{(Extreme User*innen)}

%gleiche wie vorsorierteung mit verlauf


\section{User*innenparameter}

Nach der \textit{speziellen Modellkonfiguration} sind Simulationsergebnisse in Abbildung \ref{fig:user_params_a} dargestellt. Die Verteilungen der User*innenaktivität und der Bewertungszufriedenheit werden variiert. In Abbildung  \ref{fig:user_params_b} sind die Dichteverteilungen der vier verwendeten Verteilungen dargestellt. Wie an der Viewmetrik im Fall $G_R = 0$ zu sehen ist führt die Variierung der Verteilung der Bewertungsverteilung zur Verschiebung des Mittelwerts von $T(G)$, während die Variierung der Aktivitätsverteilung zur Verschiebung des Mittelwerts von $P_{v = 0}$ und $T(nDCG)$ führt. Für den Fall $G_R = 2$ hat die Variierung der Aktivitätsverteilung keinen signifikanten Einfluss. Die Simulationsergebnisse, welche durch die Verwendung unterschiedlicher Verteilungen enstanden sind stehen in starker Korrelation. Die Ergebnisse einzelner Modellkonfigurationen ist weitesgehend unabhängig von der Wahl der Verteilungen der Bewertungszufriedenheit und der Aktivität.

\begin{figure}[!h]
	\label{fig:user_params}	
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/vote_prob_scatter.png"}
		\caption{Variierung der Verteilung von Aktivität und Bewertungszufriedenheit}
		\label{fig:user_params_a}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{"../plots/vote_prob_dists.png"}
		\caption{Dichteverteilungen der verwendeten $\beta$-Verteilungen}
		\label{fig:user_params_b}
	\end{subfigure}
	\caption{User*innenparameter}
\end{figure}

Für die Konzentrationsverteilung ergibt sich das gleiche Bild. Wird der Erwartungswert der Konzentrationsverteilung erhöht, so verringert sich $T(G)$. 

Wird der Erwartungswert der poisson-verteilten Konzentration erhöht, so verringert sich $T(G)$ und $P_{v=0}$. Dies ist intuitiv, da User*innen mehr Posts betrachten und so auch diese sehen, welche von der Bewertungsmetrik schlechter bewertet wurden. Durch die Wahl der Konzentrationsverteilung wird ebenso wenig das Ergebnis einzelner Modellkonfigurationen beeinflusst.







