\chapter{Fazit und Ausblick}

In dieser Arbeit wurde ein agent*innenbasiertes Modell zur Simulation einer Social Media Plattform entwickelt und in Julia implementiert. Auf der modellierten Plattform können User*innen mit Posts interagieren indem sie diese bewerten. Das Nutzer*innenverhalten wird für Plattformen auf denen Konsens und Dissens herrscht stochastisch modelliert. Es werden vier Bewertungsmetriken, darunter die Reddit Hot und die Hacker News Metrik eingeführt. Die Bewertungsmetrik mit dem Initialscore, der Zufallsabweichung und der Bewertungstransformation weitere variable Parameter. Für diese Bewertungsmetriken wurde ein Fairnessbegriff eingeführt, anhand dessen die Bewertungsmetriken vergleichbar werden. Über ein in Julia entwickeltes Framework können Modellkonfigurationen definiert und berechnet werden. Die Simulationsergebnisse zeigen, dass die Bewertungsmetriken sich in unterschiedlichen Konfigurationen in der Fairness unterscheiden. Die Auswahl der idealen Bewertungsmetrik hängt von der Art der Social Media Plattform ab.


In dieser Arbeit wurde eine agent*innenbasiertes Modell von Votingsystemen zur Simulation einer Social Media Plattform entwickelt und in Julia implementiert. User*innen können auf dieser Plattform mit Posts interagieren, indem sie diese auf durch das Votingsystem vorgebene Art bewerten. Mithilfe dieser Simulation können Bewertungsmetriken nach einem definiertem Fairnessbegriff verglichen und analysiert werden. Durch ein in Julia entwickeltes Framework können unterschiedliche Konfigurationen des Modells und Bewertungsmetriken definiert und simuliert werden. Ausgewählte Bewertungsmetriken, darunter die Reddit Hot und die Hacker News Metrik werden vorgestellt auf unterschiedlichen Plattformarten, Q\&A- und News-Plattformen, jene auf welchen Konsens oder Dissens herrscht, berechnet. Die Ergebnisse zeigen auf, dass Bewertungsmetriken sich durchaus in der Fairness unterscheiden und die Wahl der idealen Bewertungsmetrik von der Art der Plattform abhängig ist.


\chapter*{Ausblick}

Die Simulationen wurden mit kleinen Iterationlängen, User*innen- und Postanzahlen durchgeführt. Einige Bewertungsmetriken werden durch eine höhere Iterationszahl besser, während andere im Ergebnis stabil bleiben. Wird die Iterationslänge, wie die User*innen- und Postanzahlen erhöht, werden die Ergebnisse genauer und ermöglichen besseren Aufschluss, welche Bewertungsmetrik am fairsten ist.

Die Implementierung ist beschränkt auf Votingsysteme mit  $B_N = {1,2}$, Modelle welche User*innen Posts nur positiv oder positiv und negativ bewerten können. Es zeigt sich, dass die duale Bewertungsmodelle in mehr Konfigurationen bessere Ergebnisse liefert. Es ist interessant zu untersuchen wie sich Modelle mit größeren $B_N > 2$ verhalten.

Im Modell sind die Verteilungen, welche das User*innenverhalten definieren nicht korreliert. Dies ist in der Realität jedoch sicherlich der Fall. Nutzer*innen welche häufig aktiv sind weisen meist auch ein ausgeprägteres Bewertungsverhalten aus, sie bewerten Posts häufiger. Eine zukünftige Arbeit könnte die User*innenparameter in Korrelation setzen.

Wenn User*innen im Modell einen Post betrachten, entscheiden sie rein nach der wahrgenommenen Qualität, ob und wie sie den Post bewerten. Der soziale Einfluss, der in einem realem System durch die angezeigten Bewertungen entsteht wird in diesem Modell nicht erfasst. Um dies zu realisieren muss die Bewertungzufriedenheit durch den neuen sozialen Einfluss angepasst werden.

Die Framework bietet die einfache Definition von neuen Bewertungsmetriken und deren Parameter. In \cite{dietze} wird das \textit{Dirichlet Smoothing} verwendet und die Bewertungen der Posts zu transformieren, dies könnte ebenfalls implementiert und getestet werden. Aktuell können nur fixe Initialscores für Posts angegeben werden, es ist jedoch auch denkbar die Initialscores dynamisch zu berechnen. Neue Posts könnten zum Beispiel immer den Mittelwert der aktuellen Scores der Posts als Initialwert erhalten.

Der Featureraum für die Parameter der Bewertungsmetrik und des Votingsystems kann begrenzt werden, sodass ein Optimierungsproblem formuliert werden kann und zum Beispiel nach der Minimierung von $\rho$ optimiert werden kann. So wäre es möglich für eine bestimmte Plattformart die optimale Bewertungsmetrik zu finden.
%TODO Aufstellung eines Optimierungsproblems um die optimale Bewertungsmetrik zu finden.