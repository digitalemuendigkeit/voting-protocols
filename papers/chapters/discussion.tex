\chapter{Diskussion der Ergebnisse}

%TODO R_G in R_\gamma umbenennen
Die unterschiedlichen Bewertungsmetriken wurden für eine Q\&A-Plattoform mit $R_\gamma = 0$ und einer News-Plattform mit $R_\gamma = 2$ simuliert, mit jeweils den User*innenmeinungsfunktionen Konsens und Dissens modelliert.

Bereits die Wahl des Votingsystems bzw. des Bewertungsraums hat Einfluss auf die Fairness einer Bewertungsmetrik. In dieser Simulation ist ein größerer Bewertungsraum von $V_N = 2$ in den meisten Fällen fairer. Jedoch gibt es insbesondere auf News-Plattformen einige Konfigurationen mit $V_N = 1$ welche besser abschneiden. Es lässt sich nicht mit Gewissheit sagen, welcher Bewertungsraum zur einer faireren Bewertungsmetrik führt, außerdem ist es interessant größere $V_N$ zu untersuchen.

Die in \cite{Luu} vorgeschlagene zufällige Abweichung führt in dieser Simulation zur Verbesserung von Metriken auf News- und Dissens-Plattformen . Der aggregierte Gini-Koeffizient $T(G)$ und die Anzahl der Posts ohne Betrachtungen kann signifikant reduziert werden, während der aggregierte nDCG $T(nDCG)$ stabil bleibt. Hier empfiehlt sich die Anwendung einer zufälligen Abweichung. 

In \cite{miller} wird der Wilson-Score vorgeschlagen um Up- und Downvotes eines Posts zu evaluieren, die Bewertung des Posts zu transformieren. In der Simulation zeigt sich, dass der Wilson Score nicht in allen Fällen der Differenz auf Up- und Downvotes überlegen. Auf einer Q\&A-Plattform auf der Konsens herrscht ist die Differenz-Bewertungstransformation überlegen.

Bewertungsmetriken liefern bessere Ergebnisse, wenn Posts mit einem Initialscore $\iota_0 > 0$ ausgestattet werden. Die Wahl des besten Initialscores ist von der Bewertungsmetrik abhängig. Bei dem Initialscore $\iota_0 = 0$ werden die neuen Posts unter allen bereits existierenden Posts angezeigt und erhalten somit nur sehr wenige Views. Sobald $\iota_0 > 0$ gewählt wird, erhalten neue Posts von Beginn an Betrachtungen, gute Posts erhalten so die Chance gute Bewertungen zu erhalten.
Für die Reddit Hot Metrik konnte kein optimaler Initialscore ermittelt werden, es ist jedoch zu vermuten das dieser, wie bei den drei weiteren Metriken, weder kleiner noch größer als die Scores sämtlicher Posts der Bewertungsmetrik zu wählen ist.

Die Wahl der Gravität hat einen großen Einfluss auf die Fairness von Bewertungsmetriken, diese sollte daher mit Bedacht gewählt werden. Während auf einer Q\&A-Plattform kleine Gravitäten $\gamma = 0 + \epsilon, \epsilon = {0, 0.5}$ vorteilhaft sind, ist auf einer News-Plattform am besten $\gamma = 2$ zu wählen. Möglicherweise ist für $R_\gamma \approx \gamma$ die Bewertungsmetrik am fairsten.

Die Evaluationsparameter $T(G)$ und $P_{v=0}$ sind mit einem Spearman-Koeffizienten von $0.92$ in der \texttt{Überblick}-Konfiguration sehr stark korreliert. Auch der Gini-Koeffizient achtet implizit auf die Anzahl der Posts ohne Betrachtungen, worauf diese hohe Korrelation zurückzuführen ist. %Der Gini-Koeffizient findet viel Anwendung in der existierenden Literatur, da sich die Anzahl der Posts ohne Betrachtungen jedoch direkt aus der Fairnessdefinition einer Bewertungsmetrik ergibt wird $P_{v=0}$ vorgezogen.

In dieser Arbeit wurde der sehr große Featureraum nicht vollständig exploriert. Einzelne Metrikparameter wie der Initialscore werden nur unter bestimmten Modellkonfigurationen simuliert und verglichen. Es ist möglich, dass Kombinationen von Metrikparametern sehr gute Ergebnisse liefern, zu diesen aber keine Simulation ausgeführt wurde und sie nicht entdeckt wurden. Mit Gewissheit kann nicht gesagt werden welche Bewertungsmetirk unter einer bestimmten Konfiguration auf einer der Plattformarten am fairsten ist. Es zeigt sich jedoch, dass durch die Wahl der Bewertungsmetrik die Fairness der Sortierung von Posts beeinflusst und damit die fairste Bewertungsmetrik im Featureraum gefunden werden kann.


\paragraph{Einfluss der Modell- und User*innenparameter}

Die User*innenmeinungsfunktion kann je nach Plattform die modelliert werden soll als Konsens (technische Plattform) oder als Dissens (Diskussionsplattform) gewählt werden. Wird eine News-Plattform modelliert sind die Ergebenisse im Konsens und Dissens sehr stark korreliert. Die hohe Relevanzgravität auf der News-Plattform scheint die unterschiedlichen Meinungsfunktionen zu egalisieren. Die User*innenmeinungsfunktionen betrachtet nur die Qualität eines Postes und nicht das Alter, dieses wird jedoch bei einer hohen Relevanzgravität bestraft. Es entsteht eine grundsätzliche Abweichung zwischen der Relevanz und Meinungsfunktionen von älteren Posts. Diese kann in einer zukünftigen Implementierung durch das Einfließen der Relevanzgravität in die User*innenmeinungsfunktion verhindert werden.

Die Vergleichbarkeit der Ergebnisse ist nicht unmittelbar abhängig von der Wahl der User*innenparameter. Zwar können die Ergebnisse zum Beispiel durch die Wahl der Konzentrationsverteilung bezüglich des aggregierten Gini-Koeffizienten verschoben werden, jedoch erfahren sämtliche Modellkonfigurationen diese Verschiebung, sodass keine einzelnen Modellkonfigurationen durch die bestimmte Wahl der User*innenparameter bevorteilt wird.

Die Erhöhung der Iterationsanzahl führt erwartungsgemäß zu einer Verringerung der Varianz und damit Präzisierung der betrachteten Ergebnisparameter. Im Fall von Q\&A-Plattformen werden einzelne Bewertungsmetriken von hohen Iterationszahlen bevorzugt, sie liefern dort bessere Ergebnisse. Die Veränderung mit steigender Iterationszahl ist jedoch kontinuierlich, es treten keine unerwarteten Entwicklungen auf. Um die Langzeitperformance der Bewertungsmetriken zu analysieren ist es durchaus interessant die Iterationszahl weiter zu erhöhen.

%TODO Test der Normalverteilungen
Erfreulicherweise scheinen die Änderungen des Qualitätsraum keinen Einfluss auf die Vergleichbarkeit der Ergebnisse, keine Bewertungsmetrik wird durch die bestimmte Wahl eines Qualitätsraums bervorteiligt. Der Qualitätsraum ist nicht bekannt und muss artifiziell erzeugt werden, ohne Einfluss auf die Vergleichbarkeit der Ergebnisse kann der Qualitätsraum beliebig gewählt werden, eine realitätsgetreue Modellierung ist nicht notwendig.

Auch die Variierung der Post- und User*innenzahlen hat keinen gravierenden Einfluss auf die Vergleichbarkeit der Ergebnisse. Wie zu Erwarten steigt mit zunehmender Postanzahl der Gini-Koeffizient und die Anzahl der Posts ohne Betrachtungen. Auf einer reellen Social Media Plattform ist die Anzahl der User*innen und Posts um ein vielfaches größer als in dieser Simulation, es ist sicherlich aufschlussreich sich näher an die reellen Zahlen heranzutasten um zu überprüfen ob die Vergleichbarkeit der Ergebnisse erhalten bleibt, sodass in der Simulation weiterhin kleine User*innen- und Postanzahlen verwendet werden können.